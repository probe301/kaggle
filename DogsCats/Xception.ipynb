{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T05:38:01.426000Z",
     "start_time": "2017-10-17T05:38:01.403000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Continuum Analytics, Inc.| (default, Aug 14 2017, 13:41:13) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T07:51:25.409000Z",
     "start_time": "2017-10-17T07:51:25.214500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.8'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T05:38:29.518000Z",
     "start_time": "2017-10-17T05:38:23.501000Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xcep_model = keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T05:38:29.527000Z",
     "start_time": "2017-10-17T05:38:29.521000Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T06:51:40.505000Z",
     "start_time": "2017-10-17T06:51:40.464000Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_image(path):\n",
    "    img = image.load_img(path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def image_preprocess_and_predict(path, model):\n",
    "    img = image.load_img(path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    print('Input image shape:', x.shape)\n",
    "    preds = model.predict(x)\n",
    "    print(np.argmax(preds))\n",
    "    print('Predicted:', decode_predictions(preds, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T05:42:52.252000Z",
     "start_time": "2017-10-17T05:42:45.174000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1, 299, 299, 3)\n",
      "463\n",
      "Predicted: [[('n02909870', 'bucket', 0.5654307)]]\n",
      "Input image shape: (1, 299, 299, 3)\n",
      "463\n",
      "Predicted: [[('n02909870', 'bucket', 0.5654307)]]\n",
      "Input image shape: (1, 299, 299, 3)\n",
      "283\n",
      "Predicted: [[('n02123394', 'Persian_cat', 0.43360224)]]\n",
      "Input image shape: (1, 299, 299, 3)\n",
      "208\n",
      "Predicted: [[('n02099712', 'Labrador_retriever', 0.4385938)]]\n",
      "Input image shape: (1, 299, 299, 3)\n",
      "187\n",
      "Predicted: [[('n02094433', 'Yorkshire_terrier', 0.33378917)]]\n",
      "Input image shape: (1, 299, 299, 3)\n",
      "248\n",
      "Predicted: [[('n02109961', 'Eskimo_dog', 0.31434378)]]\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/DataSet/dogs_vs_cats/demo/'\n",
    "\n",
    "filenames = '''\n",
    "cat.375.jpg\n",
    "cat.376.jpg\n",
    "cat.377.jpg\n",
    "dog.8120.jpg\n",
    "dog.8121.jpg\n",
    "dog.8122.jpg\n",
    "'''\n",
    "\n",
    "from sein import SeinString as ss\n",
    "for name in ss(filenames).datalines():\n",
    "    image_preprocess_and_predict(path + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T07:13:26.804000Z",
     "start_time": "2017-10-17T07:13:23.303500Z"
    }
   },
   "outputs": [],
   "source": [
    "xcmodel = keras.applications.xception.Xception(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T07:17:18.578500Z",
     "start_time": "2017-10-17T07:17:18.472000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x3aafd860>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "xcmodel.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "xcmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T06:52:45.344000Z",
     "start_time": "2017-10-17T06:52:38.511000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[ 0.50000364  0.49999642]]\n",
      "0\n",
      "[[ 0.50000364  0.49999642]]\n",
      "0\n",
      "[[ 0.50000882  0.49999118]]\n",
      "0\n",
      "[[ 0.50000787  0.49999216]]\n",
      "0\n",
      "[[ 0.50000501  0.49999499]]\n",
      "0\n",
      "[[ 0.50000334  0.49999663]]\n"
     ]
    }
   ],
   "source": [
    "for name in ss(filenames).datalines():\n",
    "    test_image = get_test_image(path + name)\n",
    "    preds = xcep_model2.predict(test_image)\n",
    "    print(np.argmax(preds))\n",
    "    print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T07:51:29.239000Z",
     "start_time": "2017-10-17T07:51:28.755500Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'D:/DataSet/dogs_vs_cats/train/'\n",
    "TEST_DIR = 'D:/DataSet/dogs_vs_cats/test/'\n",
    "\n",
    "ROWS = 299\n",
    "COLS = 299\n",
    "CHANNELS = 3\n",
    "\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "TRAIN_SAMPLE = 1000 and 100\n",
    "TEST_SAMPLE = 50\n",
    "# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n",
    "train_images = train_dogs[:TRAIN_SAMPLE] + train_cats[:TRAIN_SAMPLE]\n",
    "random.shuffle(train_images)\n",
    "test_images =  test_images[:TEST_SAMPLE]\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, ROWS, COLS, CHANNELS, ), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        \n",
    "        data[i] = image\n",
    "        # data[i] = image.T \n",
    "        # print(img.shape, img.T.shape)\n",
    "        # => (299, 299, 3) (3, 299, 299)\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T07:51:33.923500Z",
     "start_time": "2017-10-17T07:51:32.725000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 200\n",
      "Processed 0 of 50\n",
      "Train shape: (200, 299, 299, 3)\n",
      "Test shape: (50, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "train = prep_data(train_images)\n",
    "test = prep_data(test_images)\n",
    "\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "print(\"Test shape: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T07:51:36.676000Z",
     "start_time": "2017-10-17T07:51:36.652500Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "# print(train_images[:10])\n",
    "for i in train_images:\n",
    "    if 'dog.' in i:      # folder name contain D:/DataSet/dogs_vs_cats/\n",
    "        labels.append((1, 0))\n",
    "    else:\n",
    "        labels.append((0, 1))\n",
    "# print(labels[:10])\n",
    "# sns.countplot(labels)\n",
    "# plt.title('Cats and Dogs')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T08:44:05.276500Z",
     "start_time": "2017-10-17T08:00:10.847000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " current epoch 150/200  elapse 467.30loss 0.574591871103 val_loss 0.694159674644\n",
      " current epoch 150/200  elapse 980.77loss 0.461858791113 val_loss 0.694163739681\n",
      " current epoch 150/200  elapse 1502.58loss 0.493965038657 val_loss 0.694308996201\n",
      " current epoch 150/200  elapse 2044.95loss 0.314564647277 val_loss 0.694744849205\n",
      " current epoch 150/200  elapse 2569.71loss 0.232443934182 val_loss 0.696743631363\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-1ba0d8eb4e86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_catdog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-1ba0d8eb4e86>\u001b[0m in \u001b[0;36mrun_catdog\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "## Callback for loss logging per epoch\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def on_batch_end(self, batch_idx, logs={}):\n",
    "        info = '\\r current epoch {}/{}  elapsed {:.2f}'\n",
    "        info = info.format(batch_size*(batch_idx+1), TRAIN_SAMPLE*2, time.time() - self.start_time)\n",
    "        print(info, end='', flush=True)\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        print('loss', logs.get('loss'), 'val_loss', logs.get('val_loss'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')        \n",
    "        \n",
    "def run_catdog():\n",
    "    \n",
    "    history = LossHistory()\n",
    "    xcmodel.fit(train, labels, batch_size=batch_size, epochs=epochs,\n",
    "                validation_split=0.25, verbose=0, shuffle=True, callbacks=[history, early_stopping])\n",
    "    \n",
    "\n",
    "    predictions = xcmodel.predict(test, verbose=0)\n",
    "    return predictions, history\n",
    "\n",
    "predictions, history = run_catdog()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T08:48:09.174000Z",
     "start_time": "2017-10-17T08:47:02.903000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48687351,  0.51312655],\n",
       "       [ 0.48689407,  0.51310593],\n",
       "       [ 0.48691782,  0.51308215],\n",
       "       [ 0.4869298 ,  0.51307017],\n",
       "       [ 0.48686993,  0.51313013],\n",
       "       [ 0.4867498 ,  0.51325023],\n",
       "       [ 0.48720551,  0.51279449],\n",
       "       [ 0.48686895,  0.51313114],\n",
       "       [ 0.48667136,  0.51332867],\n",
       "       [ 0.48705131,  0.51294863],\n",
       "       [ 0.48722267,  0.51277733],\n",
       "       [ 0.48690814,  0.5130918 ],\n",
       "       [ 0.48682782,  0.51317227],\n",
       "       [ 0.48660505,  0.51339495],\n",
       "       [ 0.48675805,  0.51324189],\n",
       "       [ 0.48732266,  0.51267731],\n",
       "       [ 0.48688251,  0.51311749],\n",
       "       [ 0.48690051,  0.51309949],\n",
       "       [ 0.4870477 ,  0.51295233],\n",
       "       [ 0.48670515,  0.51329488],\n",
       "       [ 0.48716035,  0.51283967],\n",
       "       [ 0.48679852,  0.51320142],\n",
       "       [ 0.48639536,  0.51360458],\n",
       "       [ 0.48678747,  0.51321256],\n",
       "       [ 0.48719829,  0.51280177],\n",
       "       [ 0.48698324,  0.51301682],\n",
       "       [ 0.48684782,  0.51315218],\n",
       "       [ 0.48715889,  0.51284111],\n",
       "       [ 0.48716232,  0.51283759],\n",
       "       [ 0.48697478,  0.51302516],\n",
       "       [ 0.48662341,  0.51337659],\n",
       "       [ 0.48732382,  0.51267618],\n",
       "       [ 0.48664957,  0.51335037],\n",
       "       [ 0.48722097,  0.51277906],\n",
       "       [ 0.48705268,  0.51294732],\n",
       "       [ 0.48661518,  0.51338482],\n",
       "       [ 0.48688555,  0.51311439],\n",
       "       [ 0.48655951,  0.51344055],\n",
       "       [ 0.4868187 ,  0.51318133],\n",
       "       [ 0.48680165,  0.51319832],\n",
       "       [ 0.48683131,  0.51316863],\n",
       "       [ 0.48655912,  0.51344091],\n",
       "       [ 0.48647049,  0.51352948],\n",
       "       [ 0.48686317,  0.5131368 ],\n",
       "       [ 0.48690662,  0.51309341],\n",
       "       [ 0.48722854,  0.51277149],\n",
       "       [ 0.48683929,  0.51316071],\n",
       "       [ 0.48699808,  0.51300192],\n",
       "       [ 0.48671776,  0.51328218],\n",
       "       [ 0.48691085,  0.51308912]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = xcmodel.predict(test, verbose=0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.losses\n",
    "val_loss = history.val_losses\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0, epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    if predictions[i, 0] >= 0.5: \n",
    "        print('I am {:.2%} sure this is a Dog'.format(predictions[i][0]))\n",
    "    else: \n",
    "        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i][0]))\n",
    "        \n",
    "    plt.imshow(test[i].T)\n",
    "    plt.show(figsize=(2,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
