{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Introduction\n\n**_Poonam Ligade_**\n\n*27th Dec 2016*\n\nI am are trying to find out how many people on titanic survived from disaster.\n\nHere goes Titanic Survival Prediction End to End ML Pipeline  \n\n 1) **Introduction**\n\n 1. Import Libraries\n 2. Load data\n 3. Run Statistical summeries\n 4. Figure out missing value columns\n\n \n \n2) **Visualizations**\n\n 1. Correlation with target variable\n\n\n3) **Missing values imputation**\n\n 1. train data Missing columns- Embarked,Age,Cabin\n 2. test data Missing columns- Age and Fare\n \n\n4) **Feature Engineering**\n\n 1. Calculate total family size\n 2. Get title from name\n 3. Find out which deck passenger belonged to\n 4. Dealing with Categorical Variables\n     * Label encoding\n 5. Feature Scaling\n\n\n5) **Prediction**\n\n 1. Split into training & test sets\n 2. Build the model\n 3. Feature importance\n 4. Predictions\n 5. Ensembling : Majority voting\n\n6) **Submission**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Import libraries\n================",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# We can use the pandas library in python to read in the csv file.\nimport pandas as pd\n#for numerical computaions we can use numpy library\nimport numpy as np",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Load train & test data\n======================",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# This creates a pandas dataframe and assigns it to the titanic variable.\ntitanic = pd.read_csv(\"../input/train.csv\")\n# Print the first 5 rows of the dataframe.\ntitanic.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic_test = pd.read_csv(\"../input/test.csv\")\n#transpose\ntitanic_test.head().T\n#note their is no Survived column here which is our target varible we are trying to predict",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#shape command will give number of rows/samples/examples and number of columns/features/predictors in dataset\n#(rows,columns)\ntitanic.shape",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Describe gives statistical information about numerical columns in the dataset\ntitanic.describe()\n#you can check from count if there are missing vales in columns, here age has got missing values",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#info method provides information about dataset like \n#total values in each column, null/not null, datatype, memory occupied etc\ntitanic.info()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#lets see if there are any more columns with missing values \ntitanic.isnull().sum()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**yes even Embarked and cabin has missing values.**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#how about test set??\ntitanic_test.isnull().sum()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Age, Fare and cabin has missing values.\nwe will see how to fill missing values next.**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Visualizations\n==============",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1)\n\npd.options.display.mpl_style = 'default'\ntitanic.hist(bins=10,figsize=(9,7),grid=False)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**we can see that Age and Fare are measured on very different scaling. So we need to do feature scaling before predictions.**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "g = sns.FacetGrid(titanic, col=\"Sex\", row=\"Survived\", margin_titles=True)\ng.map(plt.hist, \"Age\",color=\"purple\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "g = sns.FacetGrid(titanic, hue=\"Survived\", col=\"Pclass\", margin_titles=True,\n                  palette={1:\"seagreen\", 0:\"gray\"})\ng=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "g = sns.FacetGrid(titanic, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n                palette=\"Set1\",hue_kws=dict(marker=[\"^\", \"v\"]))\ng.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('Survival by Gender , Age and Fare')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic.Embarked.value_counts().plot(kind='bar', alpha=0.55)\nplt.title(\"Passengers per boarding location\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.factorplot(x = 'Embarked',y=\"Survived\", data = titanic,color=\"r\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.set(font_scale=1)\ng = sns.factorplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\",\n                    data=titanic, saturation=.5,\n                    kind=\"bar\", ci=None, aspect=.6)\n(g.set_axis_labels(\"\", \"Survival Rate\")\n    .set_xticklabels([\"Men\", \"Women\"])\n    .set_titles(\"{col_name} {col_var}\")\n    .set(ylim=(0, 1))\n    .despine(left=True))  \nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('How many Men and Women Survived by Passenger Class')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ax = sns.boxplot(x=\"Survived\", y=\"Age\", \n                data=titanic)\nax = sns.stripplot(x=\"Survived\", y=\"Age\",\n                   data=titanic, jitter=True,\n                   edgecolor=\"gray\")\nsns.plt.title(\"Survival by Age\",fontsize=12)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic.Age[titanic.Pclass == 1].plot(kind='kde')    \ntitanic.Age[titanic.Pclass == 2].plot(kind='kde')\ntitanic.Age[titanic.Pclass == 3].plot(kind='kde')\n # plots an axis lable\nplt.xlabel(\"Age\")    \nplt.title(\"Age Distribution within classes\")\n# sets our legend for our graph.\nplt.legend(('1st Class', '2nd Class','3rd Class'),loc='best') ",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "corr=titanic.corr()#[\"Survived\"]\nplt.figure(figsize=(10, 10))\n\nsns.heatmap(corr, vmax=1, square=True,annot=True,cmap='cubehelix')\nplt.title('Correlation between features')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#correlation of features with target variable\ntitanic.corr()[\"Survived\"]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Looks like Pclass has got highest negative correlation with \"Survived\" followed by Fare, Parch and Age** ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "g = sns.factorplot(x=\"Age\", y=\"Embarked\",\n                    hue=\"Sex\", row=\"Pclass\",\n                    data=titanic[titanic.Embarked.notnull()],\n                    orient=\"h\", size=2, aspect=3.5, \n                   palette={'male':\"purple\", 'female':\"blue\"},\n                    kind=\"violin\", split=True, cut=0, bw=.2)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Missing Value Imputation\n========================\n\n**Its important to fill missing values, because some machine learning algorithms can't accept them eg SVM.**\n\n*But filling missing values with mean/median/mode is also a prediction which may not be 100% accurate, instead you can use models like Decision Trees and Random Forest which handle missing values very well.*",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Embarked Column**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Lets check which rows have null Embarked column\ntitanic[titanic['Embarked'].isnull()]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**PassengerId 62 and 830** have missing embarked values\n\nBoth have ***Passenger class 1*** and ***fare $80.***\n\nLets plot a graph to visualize and try to guess from where they embarked",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=titanic)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('C')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can see that for ***1st class*** median line is coming around ***fare $80*** for ***embarked*** value ***'C'***.\nSo we can replace NA values in Embarked column with 'C'",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#there is an empty fare column in test set\ntitanic_test.describe()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***Fare Column***",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic_test[titanic_test['Fare'].isnull()]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#we can replace missing value in fare by taking median of all fares of those passengers \n#who share 3rd Passenger class and Embarked from 'S' \ndef fill_missing_fare(df):\n    median_fare=df[(df['Pclass'] == 3) & (df['Embarked'] == 'S')]['Fare'].median()\n#'S'\n       #print(median_fare)\n    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n    return df\n\ntitanic_test=fill_missing_fare(titanic_test)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Feature Engineering\n===================",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***Deck- Where exactly were passenger on the ship?***",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic[\"Deck\"]=titanic.Cabin.str[0]\ntitanic_test[\"Deck\"]=titanic_test.Cabin.str[0]\ntitanic[\"Deck\"].unique() # 0 is for null values",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "g = sns.factorplot(\"Survived\", col=\"Deck\", col_wrap=4,\n                    data=titanic[titanic.Deck.notnull()],\n                    kind=\"count\", size=2.5, aspect=.8)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic = titanic.assign(Deck=titanic.Deck.astype(object)).sort(\"Deck\")\ng = sns.FacetGrid(titanic, col=\"Pclass\", sharex=False,\n                  gridspec_kws={\"width_ratios\": [5, 3, 3]})\ng.map(sns.boxplot, \"Deck\", \"Age\");",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic.Deck.fillna('Z', inplace=True)\ntitanic_test.Deck.fillna('Z', inplace=True)\ntitanic[\"Deck\"].unique() # Z is for null values",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***How Big is your family?***",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a family size variable including the passenger themselves\ntitanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]+1\ntitanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]+1\nprint(titanic[\"FamilySize\"].value_counts())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Discretize family size\ntitanic.loc[titanic[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic.loc[(titanic[\"FamilySize\"] > 1)  &  (titanic[\"FamilySize\"] < 5) , \"FsizeD\"] = 'small'\ntitanic.loc[titanic[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\n\ntitanic_test.loc[titanic_test[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic_test.loc[(titanic_test[\"FamilySize\"] >1) & (titanic_test[\"FamilySize\"] <5) , \"FsizeD\"] = 'small'\ntitanic_test.loc[titanic_test[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\nprint(titanic[\"FsizeD\"].unique())\nprint(titanic[\"FsizeD\"].value_counts())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.factorplot(x=\"FsizeD\", y=\"Survived\", data=titanic)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***Do you have longer names?***",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Create feture for length of name \n# The .apply method generates a new series\ntitanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n\ntitanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))\n#print(titanic[\"NameLength\"].value_counts())\n'''\ntitanic.loc[titanic[\"NameLength\"]>37 , \"NlengthD\"] = 'long'\ntitanic.loc[titanic[\"NameLength\"]<38 , \"NlengthD\"] = 'short'\n\ntitanic_test.loc[titanic_test[\"NameLength\"]>37 , \"NlengthD\"] = 'long'\ntitanic_test.loc[titanic_test[\"NameLength\"]<38 , \"NlengthD\"] = 'short'\n'''\n\nbins = [0, 20, 40, 57, 85]\ngroup_names = ['short', 'okay', 'good', 'long']\ntitanic['NlengthD'] = pd.cut(titanic['NameLength'], bins, labels=group_names)\ntitanic_test['NlengthD'] = pd.cut(titanic_test['NameLength'], bins, labels=group_names)\n\nsns.factorplot(x=\"NlengthD\", y=\"Survived\", data=titanic)\nprint(titanic[\"NlengthD\"].unique())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***Whats in the name?***",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import re\n\n#A function to get the title from a name.\ndef get_title(name):\n    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    #If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\n#Get all the titles and print how often each one occurs.\ntitles = titanic[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\n\n#Add in the title column.\ntitanic[\"Title\"] = titles\n\n# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\n# Also reassign mlle, ms, and mme accordingly\ntitanic.loc[titanic[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntitanic.loc[titanic[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntitanic.loc[titanic[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntitanic.loc[titanic[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\n#titanic.loc[titanic[\"Title\"].isin(['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n#                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']), \"Title\"] = 'Rare Title'\n\n#titanic[titanic['Title'].isin(['Dona', 'Lady', 'Countess'])]\n#titanic.query(\"Title in ('Dona', 'Lady', 'Countess')\")\n\ntitanic[\"Title\"].value_counts()\n\n\ntitles = titanic_test[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\n#Add in the title column.\ntitanic_test[\"Title\"] = titles\n\n# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\n# Also reassign mlle, ms, and mme accordingly\ntitanic_test.loc[titanic_test[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\ntitanic_test[\"Title\"].value_counts()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***Ticket column***",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic[\"Ticket\"].tail()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic[\"TicketNumber\"] = titanic[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntitanic[\"TicketNumber\"] = titanic[\"TicketNumber\"].apply(pd.to_numeric)\n\n\ntitanic_test[\"TicketNumber\"] = titanic_test[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntitanic_test[\"TicketNumber\"] = titanic_test[\"TicketNumber\"].apply(pd.to_numeric)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#some rows in ticket column dont have numeric value so we got NaN there\ntitanic[titanic[\"TicketNumber\"].isnull()]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic.TicketNumber.fillna(titanic[\"TicketNumber\"].median(), inplace=True)\ntitanic_test.TicketNumber.fillna(titanic_test[\"TicketNumber\"].median(), inplace=True)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Convert Categorical variables into Numerical ones\n=================================================",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n\nlabelEnc=LabelEncoder()\n\ncat_vars=['Embarked','Sex',\"Title\",\"FsizeD\",\"NlengthD\",'Deck']\nfor col in cat_vars:\n    titanic[col]=labelEnc.fit_transform(titanic[col])\n    titanic_test[col]=labelEnc.fit_transform(titanic_test[col])\n\ntitanic.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***Age Column***\n\nAge seems to be promising feature.\nSo it doesnt make sense to simply fill null values out with median/mean/mode.\n\nWe will use ***Random Forest*** algorithm to predict ages. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(titanic[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"red\")\n    sns.plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestRegressor\n#predicting missing values in age using Random Forest\ndef fill_missing_age(df):\n    \n    #Feature set\n    age_df = df[['Age','Embarked','Fare', 'Parch', 'SibSp',\n                 'TicketNumber', 'Title','Pclass','FamilySize',\n                 'FsizeD','NameLength',\"NlengthD\",'Deck']]\n    # Split sets into train and test\n    train  = age_df.loc[ (df.Age.notnull()) ]# known Age values\n    test = age_df.loc[ (df.Age.isnull()) ]# null Ages\n    \n    # All age values are stored in a target array\n    y = train.values[:, 0]\n    \n    # All the other values are stored in the feature array\n    X = train.values[:, 1::]\n    \n    # Create and fit a model\n    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n    rtr.fit(X, y)\n    \n    # Use the fitted model to predict the missing values\n    predictedAges = rtr.predict(test.values[:, 1::])\n    \n    # Assign those predictions to the full data set\n    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n    \n    return df",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic=fill_missing_age(titanic)\ntitanic_test=fill_missing_age(titanic_test)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(titanic[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"tomato\")\n    sns.plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\")\n    plt.xlim((15,100))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Feature Scaling\n===============\n\nWe can see that Age, Fare are measured on different scales, so we need to do Feature Scaling first before we proceed with predictions.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import preprocessing\n\nstd_scale = preprocessing.StandardScaler().fit(titanic[['Age', 'Fare']])\ndf_std = std_scale.transform(titanic[['Age', 'Fare']])\n\n\nstd_scale = preprocessing.StandardScaler().fit(titanic_test[['Age', 'Fare']])\ndf_std = std_scale.transform(titanic_test[['Age', 'Fare']])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Correlation of features with target \n=======================",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "titanic.corr()[\"Survived\"]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Predict Survival\n================",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Import the linear regression class\nfrom sklearn.linear_model import LinearRegression\n# Sklearn also has a helper that makes it easy to do cross validation\nfrom sklearn.cross_validation import KFold\n\n# The columns we'll use to predict the target\npredictors = [\"Pclass\", \"Sex\", \"Age\",\"SibSp\", \"Parch\", \"Fare\",\n              \"Embarked\",\"NlengthD\", \"FsizeD\", \"Title\",\"Deck\"]\ntarget=\"Survived\"\n# Initialize our algorithm class\nalg = LinearRegression()\n\n# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n# We set random_state to ensure we get the same splits every time we run this.\nkf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n\npredictions = []",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for train, test in kf:\n    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n    train_predictors = (titanic[predictors].iloc[train,:])\n    # The target we're using to train the algorithm.\n    train_target = titanic[target].iloc[train]\n    # Training the algorithm using the predictors and target.\n    alg.fit(train_predictors, train_target)\n    # We can now make predictions on the test fold\n    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n    predictions.append(test_predictions)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "predictions = np.concatenate(predictions, axis=0)\n# Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions > .5] = 1\npredictions[predictions <=.5] = 0\n\n\naccuracy=sum(titanic[\"Survived\"]==predictions)/len(titanic[\"Survived\"])\naccuracy",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\n\npredictors = [\"Pclass\", \"Sex\", \"Fare\", \"Embarked\",\"Deck\",\"Age\",\n              \"FsizeD\", \"NlengthD\",\"Title\",\"Parch\"]\n\n# Initialize our algorithm\nlr = LogisticRegression(random_state=1)\n# Compute the accuracy score for all the cross validation folds.\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\nscores = cross_val_score(lr, titanic[predictors], \n                                          titanic[\"Survived\"],scoring='f1', cv=cv)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import cross_validation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import KFold\nfrom sklearn.model_selection import cross_val_predict\n\nimport numpy as np\npredictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\",\"NameLength\", \"FsizeD\", \"Title\",\"Deck\"]\n\n# Initialize our algorithm with the default paramters\n# n_estimators is the number of trees we want to make\n# min_samples_split is the minimum number of rows we need to make a split\n# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\nrf = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, \n                            min_samples_leaf=1)\nkf = KFold(titanic.shape[0], n_folds=5, random_state=1)\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\npredictions = cross_validation.cross_val_predict(rf, titanic[predictors],titanic[\"Survived\"],cv=kf)\npredictions = pd.Series(predictions)\nscores = cross_val_score(rf, titanic[predictors], titanic[\"Survived\"],\n                                          scoring='f1', cv=kf)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "predictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\",\"NameLength\", \"FsizeD\", \"Title\",\"Deck\",\"TicketNumber\"]\nrf = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=9,min_samples_split=6, min_samples_leaf=4)\nrf.fit(titanic[predictors],titanic[\"Survived\"])\nkf = KFold(titanic.shape[0], n_folds=5, random_state=1)\npredictions = cross_validation.cross_val_predict(rf, titanic[predictors],titanic[\"Survived\"],cv=kf)\npredictions = pd.Series(predictions)\nscores = cross_val_score(rf, titanic[predictors], titanic[\"Survived\"],scoring='f1', cv=kf)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Important features\n==================",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "importances=rf.feature_importances_\nstd = np.std([rf.feature_importances_ for tree in rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\nsorted_important_features=[]\nfor i in indices:\n    sorted_important_features.append(predictors[i])\n#predictors=titanic.columns\nplt.figure()\nplt.title(\"Feature Importances By Random Forest Model\")\nplt.bar(range(np.size(predictors)), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n\nplt.xlim([-1, np.size(predictors)])\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.cross_validation import KFold\n%matplotlib inline\nimport matplotlib.pyplot as plt\n#predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\",\n #             \"FsizeD\", \"Embarked\", \"NlengthD\",\"Deck\",\"TicketNumber\"]\npredictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\", \"FsizeD\",\"NameLength\",\"Deck\",\"Embarked\"]\n# Perform feature selection\nselector = SelectKBest(f_classif, k=5)\nselector.fit(titanic[predictors], titanic[\"Survived\"])\n\n# Get the raw p-values for each feature, and transform from p-values into scores\nscores = -np.log10(selector.pvalues_)\n\nindices = np.argsort(scores)[::-1]\n\nsorted_important_features=[]\nfor i in indices:\n    sorted_important_features.append(predictors[i])\n\nplt.figure()\nplt.title(\"Feature Importances By SelectKBest\")\nplt.bar(range(np.size(predictors)), scores[indices],\n       color=\"seagreen\", yerr=std[indices], align=\"center\")\nplt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n\nplt.xlim([-1, np.size(predictors)])\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\"]\n\n# Initialize our algorithm\nlr = LogisticRegression(random_state=1)\n# Compute the accuracy score for all the cross validation folds.  \ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\nscores = cross_val_score(lr, titanic[predictors], titanic[\"Survived\"], scoring='f1',cv=cv)\nprint(scores.mean())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import AdaBoostClassifier\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"TicketNumber\"]\nadb=AdaBoostClassifier()\nadb.fit(titanic[predictors],titanic[\"Survived\"])\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\nscores = cross_val_score(adb, titanic[predictors], titanic[\"Survived\"], scoring='f1',cv=cv)\nprint(scores.mean())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Maximum Voting ensemble and Submission\n=======",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "predictions=[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"NameLength\",\"TicketNumber\"]\nfrom sklearn.ensemble import VotingClassifier\neclf1 = VotingClassifier(estimators=[\n        ('lr', lr), ('rf', rf), ('adb', adb)], voting='soft')\neclf1 = eclf1.fit(titanic[predictors], titanic[\"Survived\"])\npredictions=eclf1.predict(titanic[predictors])\npredictions\n\ntest_predictions=eclf1.predict(titanic_test[predictors])\n\ntest_predictions=test_predictions.astype(int)\nsubmission = pd.DataFrame({\n        \"PassengerId\": titanic_test[\"PassengerId\"],\n        \"Survived\": test_predictions\n    })\n\nsubmission.to_csv(\"titanic_submission.csv\", index=False)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***To do: stacking!. Watch this spaceâ€¦***",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***Hope you find it useful. :)***",
      "metadata": {}
    }
  ]
}